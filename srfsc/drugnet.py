# -*- coding: utf-8 -*-
"""drugnet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eWEUrZZMSPtTzdmHixSI-i54vrxiyR-B
"""

"""https://sites.google.com/site/ucinetsoftware/datasets/covert-networks/drugnet"""
import zipfile
import os
import numpy as np
import scipy.sparse as sp
import os
import pandas as pd


# Define ZIP file paths
zip_files = ["/content/Drugnet.zip", "/content/Drugnet CSV.zip"]
extract_path = "/content/drugnet_data"

# Extract both ZIP files
for zip_path in zip_files:
    if os.path.exists(zip_path):
        print(f"Extracting {zip_path} ...")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_path)

# List extracted files
print("Extracted files:", os.listdir(extract_path))

def load_drugnet(path: str = "drugnet_data/CSV"):
    """
    Load the DrugNet dataset (network + attributes).
    """
    # File paths
    edge_file = os.path.join(path, "DRUGNET.csv")
    attribute_file = os.path.join(path, "DRUGATTR.csv")

    # Check if files exist
    if not os.path.exists(edge_file):
        raise FileNotFoundError(f"File {edge_file} not found. Ensure dataset is extracted.")
    if not os.path.exists(attribute_file):
        raise FileNotFoundError(f"File {attribute_file} not found. Ensure dataset is extracted.")

    # **Load Adjacency Matrix with Error Handling**
    print("Loading adjacency matrix...")
    df = pd.read_csv(edge_file, encoding="utf-8", header=None)

    # Remove non-numeric characters and empty spaces
    df = df.applymap(lambda x: str(x).strip().replace('"', '').replace("'", '').replace('\ufeff', ''))

    # Convert to numeric, forcing errors to NaN
    df = df.apply(pd.to_numeric, errors="coerce")

    # Fill NaN values with 0 (assuming missing values are no connections)
    df = df.fillna(0)

    # Convert dataframe to numpy array
    edges = df.to_numpy(dtype=int)

    num_nodes = edges.shape[0]  # Assuming square adjacency matrix

    # Convert adjacency matrix to sparse format
    A = sp.coo_matrix(edges, shape=(num_nodes, num_nodes), dtype=int)

    # **Load Sensitive Attributes (Ethnicity, Gender)**
    print("Loading sensitive attributes...")
    df_attr = pd.read_csv(attribute_file, encoding="utf-8")

    # Extract Ethnicity and Gender columns (Adjust based on actual column names)
    ethnicity = df_attr.iloc[:, 1].to_numpy()  # Assuming 2nd column = ethnicity
    gender = df_attr.iloc[:, 2].to_numpy()  # Assuming 3rd column = gender

    # Ensure valid encoding (based on dataset description)
    gender_map = {1: 0, 2: 1, 0: -1}  # Convert 1=Male (0), 2=Female (1), 0=Unknown (-1)
    gender = np.array([gender_map.get(g, -1) for g in gender])

    # Stack ethnicity and gender into a single vector
    sensitivity_vector = np.stack((ethnicity, gender), axis=1)

    return A, sensitivity_vector

# Run the loader
if __name__ == "__main__":
    A, s = load_drugnet("/content/drugnet_data/CSV")
    print(f"Adjacency matrix shape: {A.shape}")
    print(f"Sensitive attribute vector shape: {s.shape}")